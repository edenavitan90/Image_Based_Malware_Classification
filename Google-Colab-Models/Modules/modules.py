def plot_confusion_matrix(cm, title, labels):   
    cmp = metrics.ConfusionMatrixDisplay(cm, display_labels=labels)
    fig, ax = plt.subplots(figsize=(17, 17))
    cmp.plot(ax=ax, values_format='.0f')
    plt.title(title)
    plt.xticks(rotation=90)

############################

def plot_hist(class_names, y_train, y_hat_train, y_test, y_hat_test, cm_train, cm_test):
    print("\nMalware family with the highest false classification:")
    train_false_classification = class_names[y_train[np.where((y_hat_train == y_train) == False)]]
    labels, count = np.unique(train_false_classification, return_counts=True)
    print("Train: ", labels[np.argmax(count)])

    test_false_classification = class_names[y_test[np.where((y_hat_test == y_test) == False)]]
    labels, count = np.unique(test_false_classification, return_counts=True)
    print("Test: ", labels[np.argmax(count)])
    
    train_labels, train_count = np.unique(y_train, return_counts=True)
    train_accuracy_by_family = np.diag(cm_train) / train_count

    test_labels, test_count = np.unique(y_test, return_counts=True)
    test_accuracy_by_family = np.diag(cm_test) / test_count

    fig, ax = plt.subplots(figsize=(16, 10))
    labels = np.arange(len(class_names))
    width = 0.25
    ax.bar(labels-width/2-0.02, test_accuracy_by_family, color="#a8c9a7", width=width, align='center')
    ax.bar(labels+width/2+0.02, train_accuracy_by_family, color="#b55e5f", width=width, align='center')
    fig.tight_layout()
    ax.set_xticks(labels)
    plt.xlim([-1, len(class_names)])
    ax.set_xticklabels(class_names)
    plt.xticks(rotation=90)
    plt.legend(["Test", "Train"], prop={'size': 16})
    plt.ylim([0, 1.11])
    plt.grid(True)
    plt.show()

