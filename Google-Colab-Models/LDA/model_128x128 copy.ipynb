{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46dd4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "malware_family = {\"Adialer.C\": 0, \"Agent.FYI\": 1, \"Allaple.A\": 2, \"Allaple.L\": 3, \"Alueron.gen!J\": 4, \"Autorun.K\": 5, \"C2LOP.gen!g\": 6,\n",
    "                  \"C2LOP.P\": 7, \"Dialplatform.B\": 8, \"Dontovo.A\": 9, \"Fakerean\": 10, \"Instantaccess\": 11, \"Lolyda.AA1\": 12, \"Lolyda.AA2\": 13,\n",
    "                  \"Lolyda.AA3\": 14, \"Lolyda.AT\": 15, \"Malex.gen!J\": 16, \"Obfuscator.AD\": 17, \"Rbot!gen\": 18, \"Skintrim.N\": 19, \"Swizzor.gen!E\": 20,\n",
    "                  \"Swizzor.gen!I\": 21, \"VB.AT\": 22, \"Wintrim.BX\": 23, \"Yuner.A\": 24}\n",
    "\n",
    "class_names = np.array([\"Adialer.C\", \"Agent.FYI\", \"Allaple.A\", \"Allaple.L\", \"Alueron.gen!J\", \"Autorun.K\", \"C2LOP.gen!g\",\n",
    "                  \"C2LOP.P\", \"Dialplatform.B\", \"Dontovo.A\", \"Fakerean\", \"Instantaccess\", \"Lolyda.AA1\", \"Lolyda.AA2\",\n",
    "                  \"Lolyda.AA3\", \"Lolyda.AT\", \"Malex.gen!J\", \"Obfuscator.AD\", \"Rbot!gen\", \"Skintrim.N\", \"Swizzor.gen!E\",\n",
    "                  \"Swizzor.gen!I\", \"VB.AT\", \"Wintrim.BX\", \"Yuner.A\"])\n",
    "    \n",
    "path = \"../../Dataset And Mapping/mapped-128x128-data.xlsx\"\n",
    "\n",
    "if os.path.isfile(path):\n",
    "    data = pd.read_excel(path)\n",
    "else:\n",
    "    print(\"\\n\")\n",
    "    print(\"\\t\\t\" + 89 * \"*\")\n",
    "    print(\"\\t\\t\" + f\"*\\tThe file: '{path}' is NOT exist.\\t*\")\n",
    "    print(\"\\t\\t\" + f\"*\\tPlease run 'Dataset And Mapping/data_organizer_automation.py' to create it.\\t*\")\n",
    "    print(\"\\t\\t\" + 89 * \"*\" + \"\\n\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7c518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title, labels):\n",
    "    \n",
    "    cmp = metrics.ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(17, 17))\n",
    "    cmp.plot(ax=ax, values_format='.0f')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b17b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(class_names, train_count , test_count, cm_train, cm_test):\n",
    "# def plot_hist(class_names, y_train , y_test, cm_train, cm_test):\n",
    "# def plot_hist(class_names, y_train ''', y_hat_train''', y_test ''', y_hat_test''', cm_train, cm_test):\n",
    "\n",
    "#     print(\"\\nMalware family with the highest false classification:\")\n",
    "#     train_false_classification = class_names[y_train[np.where((y_hat_train == y_train) == False)]]\n",
    "#     labels, count = np.unique(train_false_classification, return_counts=True)\n",
    "#     print(\"Train: \", labels[np.argmax(count)])\n",
    "\n",
    "#     test_false_classification = class_names[y_test[np.where((y_hat_test == y_test) == False)]]\n",
    "#     labels, count = np.unique(test_false_classification, return_counts=True)\n",
    "#     print(\"Test: \", labels[np.argmax(count)])\n",
    "    \n",
    "    # train_labels, train_count = np.unique(y_train, return_counts=True)\n",
    "    train_accuracy_by_family = np.diag(cm_train) / train_count\n",
    "\n",
    "    # test_labels, test_count = np.unique(y_test, return_counts=True)\n",
    "    test_accuracy_by_family = np.diag(cm_test) / test_count\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 10))\n",
    "    labels = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "    ax.bar(labels-width/2-0.02, test_accuracy_by_family, color=\"#a8c9a7\", width=width, align='center')\n",
    "    ax.bar(labels+width/2+0.02, train_accuracy_by_family, color=\"#b55e5f\", width=width, align='center')\n",
    "    fig.tight_layout()\n",
    "    ax.set_xticks(labels)\n",
    "    plt.xlim([-1, len(class_names)])\n",
    "    ax.set_xticklabels(class_names)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend([\"Test\", \"Train\"], prop={'size': 16})\n",
    "    plt.ylim([0, 1.11])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdb866c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_StratifiedKFold(X, Y, K):\n",
    "    skf = StratifiedKFold(n_splits=K, random_state=1, shuffle=True)\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    train_success = []\n",
    "    test_success = []\n",
    "    train_false_classification_total = []\n",
    "    test_false_classification_total = []\n",
    "    cm_train_vector = np.zeros((class_names.shape[0], class_names.shape[0]))\n",
    "    cm_test_vector = np.zeros((class_names.shape[0], class_names.shape[0]))\n",
    "    \n",
    "    y_train_count_mean_array = np.zeros(len(class_names))\n",
    "    y_test_count_mean_array = np.zeros(len(class_names))\n",
    "    \n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    \n",
    "    it = 0\n",
    "    for train_index, test_index in skf.split(X,Y):\n",
    "        \n",
    "        it += 1\n",
    "        X_train, X_test = X[train_index], X[test_index] \n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        _, train_count = np.unique(y_train, return_counts=True)\n",
    "        _, test_count = np.unique(y_test, return_counts=True)\n",
    "\n",
    "        y_train_count_mean_array += np.array(train_count)\n",
    "        y_test_count_mean_array += np.array(test_count)\n",
    "        \n",
    "        clf.fit(\n",
    "            X_train,\n",
    "            y_train\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        # y_hat_train = clf.predict(X_train)\n",
    "        y_hat_train = clf.predict(X_test)\n",
    "        cm_train = metrics.confusion_matrix(y_train, y_hat_train)\n",
    "        cm_train_vector += cm_train\n",
    "        \n",
    "        # Test\n",
    "        # y_hat_test = clf.predict(X_test)\n",
    "        y_hat_test = clf.predict(X_train)\n",
    "        cm_test = metrics.confusion_matrix(y_test, y_hat_test)\n",
    "        cm_test_vector += cm_test\n",
    "\n",
    "        train_success_rate = (y_hat_train == y_train).sum() / len(y_train)\n",
    "        test_success_rate = (y_hat_test == y_test).sum() / len(y_test)\n",
    "        \n",
    "        train_success.append(train_success_rate)\n",
    "        test_success.append(test_success_rate)\n",
    "        \n",
    "        print(\"train_success_rate:\", train_success_rate)\n",
    "        print(\"test_success_rate:\", test_success_rate)\n",
    "\n",
    "#         plot_confusion_matrix(\n",
    "#             cm_train, \n",
    "#             'Train data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(K, train_success_rate*100), \n",
    "#             class_names\n",
    "#         )\n",
    "\n",
    "#         plot_confusion_matrix(\n",
    "#             cm_test, \n",
    "#             'Test data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(K, test_success_rate*100), \n",
    "#             class_names\n",
    "#         )\n",
    "\n",
    "        # plot_hist(class_names, y_train, y_hat_train, y_test, y_hat_test, cm_train, cm_test)     # first \n",
    "        # plot_hist(class_names, y_train, y_test, cm_train, cm_test)\n",
    "        # plot_hist(class_names, train_count, test_count, cm_train, cm_test)                      # last\n",
    "        \n",
    "        train_false_classification = class_names[y_train[np.where((y_hat_train == y_train) == False)]]\n",
    "        train_false_classification_total += train_false_classification.tolist()\n",
    "        labels, count = np.unique(train_false_classification, return_counts=True)\n",
    "\n",
    "        test_false_classification = class_names[y_test[np.where((y_hat_test == y_test) == False)]]\n",
    "        test_false_classification_total += test_false_classification.tolist()\n",
    "        labels, count = np.unique(test_false_classification, return_counts=True)\n",
    "\n",
    "        print(f\"\\n{K}.{it}) Malware family with the highest false classification (without normalizing - per iteration):\")\n",
    "        print(\"\\t- Train: \", labels[np.argmax(count)])\n",
    "        print(\"\\t- Test: \", labels[np.argmax(count)])\n",
    "        \n",
    "#         print(\"\\nSuccess Rate:\")\n",
    "#         print(\"Train:\", train_success_rate)\n",
    "#         print(\"Test:\", test_success_rate)\n",
    "#         print(\"-------\")\n",
    "        # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    # Need to take these vals and convert to Dict (each of them) -> family name = key, the count = val\n",
    "    # Continue with calc as we wrote in the OneNote.\n",
    "    # can we do it with np.unique?\n",
    "    train_false_classification_lables, train_false_classification_count = np.unique(np.array(train_false_classification_total), return_counts=True)\n",
    "    test_false_classification_lables, test_false_classification_count = np.unique(np.array(test_false_classification_total), return_counts=True)\n",
    "\n",
    "    train_false_classification_dict = dict(zip(train_false_classification_lables, train_false_classification_count))\n",
    "    test_false_classification_dict = dict(zip(test_false_classification_lables, test_false_classification_count))\n",
    "    \n",
    "    '''\n",
    "    _, images_by_class_names_count = np.unique(np.array(Y), return_counts=True)\n",
    "    images_names_count_dict = dict(zip(class_names, images_by_class_names_count))\n",
    "    \n",
    "    # Train:\n",
    "    for key in train_false_classification_dict:\n",
    "        train_false_classification_dict[key] = (train_false_classification_dict[key] * (1-1/K) * 1/K) * 1/images_names_count_dict[key]\n",
    "\n",
    "    # Test: \n",
    "    for key in test_false_classification_dict:\n",
    "        test_false_classification_dict[key] = (test_false_classification_dict[key] * 1/K * 1/K) * 1/images_names_count_dict[key]\n",
    "    '''\n",
    "    train_mean = np.mean(train_success) \n",
    "    test_mean = np.mean(test_success)\n",
    "    \n",
    "    train_variance = np.var(train_success)\n",
    "    test_variance = np.var(test_success)\n",
    "        \n",
    "    return (train_mean, test_mean, train_variance, test_variance, \n",
    "            cm_train_vector/K, cm_test_vector/K, train_false_classification_dict, test_false_classification_dict,\n",
    "            y_train_count_mean_array/K, y_test_count_mean_array/K)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e57b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "i = 0\n",
    "for el in np.array(data):\n",
    "    im = Image.open(fr\"../../Dataset And Mapping/{el[1]}\")\n",
    "    X.append(np.array(im).flatten() / 255)\n",
    "    Y.append(malware_family[el[2]])\n",
    "    i += 1\n",
    "    # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8a42c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [4669, 4670]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9e93497a94cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     (train_mean, test_mean, train_variance, test_variance, \n\u001b[0;32m     21\u001b[0m      \u001b[0mcm_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcm_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtrain_false_classification_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_false_classification_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m      y_train_count, y_test_count) = run_StratifiedKFold(X, Y, k)\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-087a5639568c>\u001b[0m in \u001b[0;36mrun_StratifiedKFold\u001b[1;34m(X, Y, K)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# y_hat_train = clf.predict(X_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0my_hat_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mcm_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mcm_train_vector\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcm_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \"\"\"\n\u001b[1;32m--> 296\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [4669, 4670]"
     ]
    }
   ],
   "source": [
    "train_mean_list = []\n",
    "test_mean_list = []\n",
    "\n",
    "train_var_list = []\n",
    "test_var_list = []\n",
    "\n",
    "train_false_classification_list = []\n",
    "test_false_classification_list = []\n",
    "\n",
    "cm_train_vector = []\n",
    "cm_test_vector = []\n",
    "\n",
    "y_train_count_list = []\n",
    "y_test_count_list = []\n",
    "\n",
    "K = 2\n",
    "start = 2\n",
    "\n",
    "for k in range(start, K+1):\n",
    "    (train_mean, test_mean, train_variance, test_variance, \n",
    "     cm_train, cm_test , train_false_classification_dict, test_false_classification_dict, \n",
    "     y_train_count, y_test_count) = run_StratifiedKFold(X, Y, k)\n",
    "    \n",
    "    \n",
    "    _, images_by_class_names_count = np.unique(np.array(Y), return_counts=True)\n",
    "    images_names_count_dict = dict(zip(class_names, images_by_class_names_count))\n",
    "    \n",
    "    # Train:\n",
    "    for key in train_false_classification_dict:\n",
    "        train_false_classification_dict[key] = (train_false_classification_dict[key] * (1-1/K) * 1/K) * 1/images_names_count_dict[key]\n",
    "\n",
    "    # Test: \n",
    "    for key in test_false_classification_dict:\n",
    "        test_false_classification_dict[key] = (test_false_classification_dict[key] * 1/K * 1/K) * 1/images_names_count_dict[key]\n",
    "    \n",
    "    \n",
    "    train_mean_list.append(train_mean)\n",
    "    test_mean_list.append(test_mean)\n",
    "    \n",
    "    train_var_list.append(train_variance)\n",
    "    test_var_list.append(test_variance)\n",
    "    \n",
    "    train_false_classification_list.append(train_false_classification_dict)\n",
    "    test_false_classification_list.append(test_false_classification_dict)\n",
    "    \n",
    "    cm_train_vector.append(cm_train)\n",
    "    cm_test_vector.append(cm_test)\n",
    "    \n",
    "    y_train_count_list.append(y_train_count)\n",
    "    y_test_count_list.append(y_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67404c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(2, K+1)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(x, train_mean_list, '--', x, test_mean_list, '--', marker=\"o\")\n",
    "plt.title(\"Success Rate Depending On K\", fontsize=20)\n",
    "plt.legend([\"Train\", \"Test\"], prop={'size': 16})\n",
    "plt.ylabel('Success Rate', fontsize=14)\n",
    "plt.xlabel('K', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(x, train_var_list, '--', x, test_var_list, '--', marker=\"o\")\n",
    "plt.title(\"Variance Depending On K\", fontsize=20)\n",
    "plt.legend([\"Train\", \"Test\"], prop={'size': 16})\n",
    "plt.ylabel('Variance', fontsize=14)\n",
    "plt.xlabel('K', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# print(\"train_var_list:\", train_var_list, \"test_var_list:\", test_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving weights to each vector per its K.\n",
    "test_avg_by_K =  1 / np.linspace(start, K, K - start + 1)\n",
    "train_avg_by_K = 1 - test_avg_by_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e28909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The combined success rate of Test & Train.\n",
    "overall_mean_success_rate = np.array(train_mean_list) * train_avg_by_K + np.array(test_mean_list) * test_avg_by_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbdd9da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_K = np.argmax(overall_mean_success_rate) + 2\n",
    "best_K_success_rate = overall_mean_success_rate[np.argmax(overall_mean_success_rate)]\n",
    "print(f\"The best K (AVG - Train && Test runs) is: K = {best_K}.\")\n",
    "print(f\"Total Success Rate for this K is (AVG - Train && Test): {(best_K_success_rate * 100):.3f} %.\")\n",
    "\n",
    "print(f\"\\n***\\tResults summary for this K ({best_K})\\t***\\n\")\n",
    "\n",
    "print(f\"- Success Rate:\")\n",
    "print(f\"\\tTrain:\\t {(train_mean_list[best_K-2] * 100):.3f} %\")\n",
    "print(f\"\\tTest:\\t {(test_mean_list[best_K-2] * 100):.3f} %\")\n",
    "\n",
    "print(f\"- Distribution Ratio:\")\n",
    "print(f\"\\tTrain:\\t {((1 - 1/best_K) * 100):.3f} %\")\n",
    "print(f\"\\tTest:\\t {((1/best_K) * 100):.3f} %\")\n",
    "\n",
    "print(f\"- Number Of Images (+/- 1):\")\n",
    "print(f\"\\tTotal:\\t  {len(Y)}\")\n",
    "print(f\"\\tTrain:\\t ~{((1 - 1/best_K)) * len(Y):.0f}\")\n",
    "print(f\"\\tTest:\\t ~{((1/best_K) * len(Y)):.0f}\")\n",
    "\n",
    "train_var_reverse_sort = np.sort(np.array(train_var_list))# [::-1]\n",
    "test_var_reverse_sort = np.sort(np.array(test_var_list)) # [::-1]\n",
    "\n",
    "print(f\"- Success Rate Variance:\")\n",
    "print(f\"\\t** The 1st place is the smallest (best) **\")\n",
    "print(f\"\\tTrain:\\t {(train_var_list[best_K-2]):.3e}, [{1 + np.where(train_var_reverse_sort == train_var_list[best_K-2])[0][0]}th place out of {len(train_var_reverse_sort)}]\")\n",
    "print(f\"\\tTest:\\t {(test_var_list[best_K-2]):.3e}, [{1 + np.where(test_var_reverse_sort == test_var_list[best_K-2])[0][0]}th place out of {len(test_var_reverse_sort)}]\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "labels = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "ax.bar(labels-width/2-0.02, y_train_count_list[best_K-2], color=\"#a8c9a7\", width=width, align='center')\n",
    "ax.bar(labels+width/2+0.02, y_test_count_list[best_K-2], color=\"#b55e5f\", width=width, align='center')\n",
    "plt.title(\"Number Of Images By Family Name\", fontsize=22)\n",
    "fig.tight_layout()\n",
    "ax.set_xticks(labels)\n",
    "plt.xlim([-1, len(class_names)])\n",
    "ax.set_xticklabels(class_names)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend([\"Train\", \"Test\"], prop={'size': 18})\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5cb42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(cm_train_vector)): \n",
    "    print(f\"\\n\\tK = {i+2}\")\n",
    "    \n",
    "    print(\"\\nSuccess Rate:\")\n",
    "    print(f\"\\t- Train: {(train_mean_list[i] * 100):.3f} %\")\n",
    "    print(f\"\\t- Test: {(test_mean_list[i] * 100):.3f} %\")\n",
    "    print(f\"\\t- AVG: {(overall_mean_success_rate[i] * 100):.3f} %\")\n",
    "    \n",
    "    print(\"\\n----------\")\n",
    "    \n",
    "    train_keys = list(train_false_classification_list[i])\n",
    "    train_argmax = np.argmax(np.array(list(train_false_classification_list[i].values())))\n",
    "\n",
    "    test_keys = list(test_false_classification_list[i])\n",
    "    test_argmax = np.argmax(np.array(list(test_false_classification_list[i].values())))\n",
    "    \n",
    "    print(\"\\nMalware family with the highest false classification (after normalizing):\")\n",
    "    print(\"\\t- Train:\", train_keys[train_argmax])\n",
    "    print(\"\\t- Test:\", test_keys[test_argmax])\n",
    "    \n",
    "    print(\"\\n----------\")\n",
    "    \n",
    "    plot_confusion_matrix(\n",
    "        cm_train_vector[i], \n",
    "        'Train data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(i+2, train_mean_list[i]*100), \n",
    "        class_names\n",
    "    )\n",
    "\n",
    "    plot_confusion_matrix(\n",
    "        cm_test_vector[i], \n",
    "        'Test data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(i+2, test_mean_list[i]*100), \n",
    "        class_names\n",
    "    )\n",
    "\n",
    "    \n",
    "    print(\"\\n******************************************\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b830ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "\n",
    "print(f\"\\t\\t\\t*************************************************\")\n",
    "print(f\"\\t\\t\\t*\\tStart time: {start_time}\\t*\")\n",
    "print(f\"\\t\\t\\t*\\tEnd time: {end_time} \\t*\")\n",
    "print(f'\\t\\t\\t*\\t\\x1b[0;30;43m' + f\"Duration time: {str(end_time - start_time)}\" + '\\x1b[0m\\t\\t*')\n",
    "print(f\"\\t\\t\\t*************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deac234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# לא ברור מה הטעות - מכיוון שכאשר אני מחלק את התמונות חצי-חצי אין שום סיבה שהמודל באימון יתן תוצאות טובות יותר על פני המודל בבדיקה )(TEST)\n",
    "# הבעיה היא שהוא מנסה לגשת לסיווגים שגויים כאשר אין כאלה, אחוז ההצלחה שווה ל100 אחוז ואין שגיאות"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141d175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
