{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f5d81f",
   "metadata": {
    "id": "b3f5d81f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d28a25",
   "metadata": {
    "id": "c5d28a25",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/i560646/Desktop/Eden/ML Final Project/Image_Based_Malware_Classification/Models/Modules', '/Users/i560646/Desktop/Eden/ML Final Project/Image_Based_Malware_Classification/Models/Modules/CNN_Modules', '/Users/i560646/Desktop/Eden/ML Final Project/Image_Based_Malware_Classification/Models/GNB', '/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python39.zip', '/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9', '/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/lib-dynload', '', '/opt/homebrew/lib/python3.9/site-packages']\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.path.abspath('..'), 'Modules/CNN_Modules'))\n",
    "sys.path.insert(0, os.path.join(os.path.abspath('..'), 'Modules'))\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "import modules as mod\n",
    "\n",
    "size = 128\n",
    "\n",
    "\n",
    "malware_family = {\"Adialer.C\": 0, \"Agent.FYI\": 1, \"Allaple.A\": 2, \"Allaple.L\": 3, \"Alueron.gen!J\": 4, \"Autorun.K\": 5, \"C2LOP.gen!g\": 6,\n",
    "                  \"C2LOP.P\": 7, \"Dialplatform.B\": 8, \"Dontovo.A\": 9, \"Fakerean\": 10, \"Instantaccess\": 11, \"Lolyda.AA1\": 12, \"Lolyda.AA2\": 13,\n",
    "                  \"Lolyda.AA3\": 14, \"Lolyda.AT\": 15, \"Malex.gen!J\": 16, \"Obfuscator.AD\": 17, \"Rbot!gen\": 18, \"Skintrim.N\": 19, \"Swizzor.gen!E\": 20,\n",
    "                  \"Swizzor.gen!I\": 21, \"VB.AT\": 22, \"Wintrim.BX\": 23, \"Yuner.A\": 24}\n",
    "\n",
    "class_names = np.array([\"Adialer.C\", \"Agent.FYI\", \"Allaple.A\", \"Allaple.L\", \"Alueron.gen!J\", \"Autorun.K\", \"C2LOP.gen!g\",\n",
    "                  \"C2LOP.P\", \"Dialplatform.B\", \"Dontovo.A\", \"Fakerean\", \"Instantaccess\", \"Lolyda.AA1\", \"Lolyda.AA2\",\n",
    "                  \"Lolyda.AA3\", \"Lolyda.AT\", \"Malex.gen!J\", \"Obfuscator.AD\", \"Rbot!gen\", \"Skintrim.N\", \"Swizzor.gen!E\",\n",
    "                  \"Swizzor.gen!I\", \"VB.AT\", \"Wintrim.BX\", \"Yuner.A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85fad62",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f85fad62",
    "outputId": "d79f6836-ea55-4993-b96e-3de002bc21e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on a local machine.\n",
      "\n",
      "Files in the current directory: ['GNB', 'Test', 'LDA', 'eden_test.py', 'eden_test.ipynb', 'CNN', 'QDA', '.ipynb_checkpoints', 'Modules']\n"
     ]
    }
   ],
   "source": [
    "google_colab_package_name = 'google.colab'\n",
    "\n",
    "if google_colab_package_name in sys.modules:\n",
    "    print(f\"{google_colab_package_name!r} exists in sys.modules.\\nRunning on google colab cloud service.\\n\")\n",
    "    \n",
    "    repo = 'Image_Based_Malware_Classification'\n",
    "    path = os.path.join(os.getcwd(), repo)\n",
    "\n",
    "    if os.path.exists(path):\n",
    "      shutil.rmtree(path)\n",
    "      print(f\"{repo} directory was deleted...\\n\")\n",
    "        \n",
    "    !git clone https://github.com/edenavitan90/Image_Based_Malware_Classification.git\n",
    "    \n",
    "    path = f\"./{repo}/Dataset And Mapping/mapped-{size}x{size}-data.xlsx\"\n",
    "    file_list = os.listdir(os.getcwd())\n",
    "    \n",
    "else:\n",
    "    print(f\"Running on a local machine.\")\n",
    "    \n",
    "    path = f\"../../Dataset And Mapping/mapped-{size}x{size}-data.xlsx\"\n",
    "    file_list = os.listdir(os.path.abspath('..'))\n",
    "\n",
    "\n",
    "print(f\"\\nFiles in the current directory: {file_list}\")\n",
    "\n",
    "if os.path.isfile(path):\n",
    "    data = pd.read_excel(path)\n",
    "else:\n",
    "    print(\"\\n\")\n",
    "    print(\"\\t\\t\" + 89 * \"*\")\n",
    "    print(\"\\t\\t\" + f\"*\\tThe file: '{path}' is NOT exist.\\t*\")\n",
    "    print(\"\\t\\t\" + f\"*\\tPlease run 'Dataset And Mapping/data_organizer_automation.py' to create it.\\t*\")\n",
    "    print(\"\\t\\t\" + 89 * \"*\" + \"\\n\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0e2bc50",
   "metadata": {
    "id": "b0e2bc50"
   },
   "outputs": [],
   "source": [
    "def run_StratifiedKFold(X, Y, K):\n",
    "    skf = StratifiedKFold(n_splits=K, random_state=1, shuffle=True)\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    train_success = []\n",
    "    test_success = []\n",
    "    train_false_classification_total = []\n",
    "    test_false_classification_total = []\n",
    "    cm_train_vector = np.zeros((class_names.shape[0], class_names.shape[0]))\n",
    "    cm_test_vector = np.zeros((class_names.shape[0], class_names.shape[0]))\n",
    "    \n",
    "    y_train_count_mean_array = np.zeros(len(class_names))\n",
    "    y_test_count_mean_array = np.zeros(len(class_names))\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    \n",
    "    it = 0\n",
    "    for train_index, test_index in skf.split(X,Y):\n",
    "        \n",
    "        it += 1\n",
    "        X_train, X_test = X[train_index], X[test_index] \n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        _, train_count = np.unique(y_train, return_counts=True)\n",
    "        _, test_count = np.unique(y_test, return_counts=True)\n",
    "\n",
    "        y_train_count_mean_array += np.array(train_count)\n",
    "        y_test_count_mean_array += np.array(test_count)\n",
    "        \n",
    "        gnb.fit(\n",
    "            X_train,\n",
    "            y_train\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        y_hat_train = gnb.predict(X_train)\n",
    "        cm_train = metrics.confusion_matrix(y_train, y_hat_train)\n",
    "        cm_train_vector += cm_train\n",
    "        \n",
    "        # Test\n",
    "        y_hat_test = gnb.predict(X_test)\n",
    "        cm_test = metrics.confusion_matrix(y_test, y_hat_test)\n",
    "        cm_test_vector += cm_test\n",
    "\n",
    "        train_success_rate = (y_hat_train == y_train).sum() / len(y_train)\n",
    "        test_success_rate = (y_hat_test == y_test).sum() / len(y_test)\n",
    "        train_success.append(train_success_rate)\n",
    "        test_success.append(test_success_rate)\n",
    "\n",
    "#         plot_confusion_matrix(\n",
    "#             cm_train, \n",
    "#             'Train data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(K, train_success_rate*100), \n",
    "#             class_names\n",
    "#         )\n",
    "\n",
    "#         plot_confusion_matrix(\n",
    "#             cm_test, \n",
    "#             'Test data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(K, test_success_rate*100), \n",
    "#             class_names\n",
    "#         )\n",
    "\n",
    "        # plot_hist(class_names, y_train, y_hat_train, y_test, y_hat_test, cm_train, cm_test)     # first \n",
    "        # plot_hist(class_names, y_train, y_test, cm_train, cm_test)\n",
    "        # plot_hist(class_names, train_count, test_count, cm_train, cm_test)                      # last\n",
    "        \n",
    "        train_false_classification = class_names[y_train[np.where((y_hat_train == y_train) == False)]]\n",
    "        train_false_classification_total += train_false_classification.tolist()\n",
    "        labels, count = np.unique(train_false_classification, return_counts=True)\n",
    "\n",
    "        test_false_classification = class_names[y_test[np.where((y_hat_test == y_test) == False)]]\n",
    "        test_false_classification_total += test_false_classification.tolist()\n",
    "        labels, count = np.unique(test_false_classification, return_counts=True)\n",
    "\n",
    "        print(f\"\\n{K}.{it}) Malware family with the highest false classification (without normalizing - per iteration):\")\n",
    "        print(\"\\t- Train: \", labels[np.argmax(count)])\n",
    "        print(\"\\t- Test: \", labels[np.argmax(count)])\n",
    "        \n",
    "#         print(\"\\nSuccess Rate:\")\n",
    "#         print(\"Train:\", train_success_rate)\n",
    "#         print(\"Test:\", test_success_rate)\n",
    "#         print(\"-------\")\n",
    "        # print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    # Need to take these vals and convert to Dict (each of them) -> family name = key, the count = val\n",
    "    # Continue with calc as we wrote in the OneNote.\n",
    "    # can we do it with np.unique?\n",
    "    train_false_classification_lables, train_false_classification_count = np.unique(np.array(train_false_classification_total), return_counts=True)\n",
    "    test_false_classification_lables, test_false_classification_count = np.unique(np.array(test_false_classification_total), return_counts=True)\n",
    "\n",
    "    train_false_classification_dict = dict(zip(train_false_classification_lables, train_false_classification_count))\n",
    "    test_false_classification_dict = dict(zip(test_false_classification_lables, test_false_classification_count))\n",
    "    \n",
    "    '''\n",
    "    _, images_by_class_names_count = np.unique(np.array(Y), return_counts=True)\n",
    "    images_names_count_dict = dict(zip(class_names, images_by_class_names_count))\n",
    "    \n",
    "    # Train:\n",
    "    for key in train_false_classification_dict:\n",
    "        train_false_classification_dict[key] = (train_false_classification_dict[key] * (1-1/K) * 1/K) * 1/images_names_count_dict[key]\n",
    "\n",
    "    # Test: \n",
    "    for key in test_false_classification_dict:\n",
    "        test_false_classification_dict[key] = (test_false_classification_dict[key] * 1/K * 1/K) * 1/images_names_count_dict[key]\n",
    "    '''\n",
    "    train_mean = np.mean(train_success) \n",
    "    test_mean = np.mean(test_success)\n",
    "    \n",
    "    train_variance = np.var(train_success)\n",
    "    test_variance = np.var(test_success)\n",
    "        \n",
    "    return (train_mean, test_mean, train_variance, test_variance, \n",
    "            cm_train_vector/K, cm_test_vector/K, train_false_classification_dict, test_false_classification_dict,\n",
    "            y_train_count_mean_array/K, y_test_count_mean_array/K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257faed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "257faed7",
    "outputId": "16aeb91c-79fe-45fe-f042-3bd477021780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Last index: 9764.\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "i = 0\n",
    "for el in np.array(data):\n",
    "    if google_colab_package_name in sys.modules:\n",
    "        image_path = fr\"./{repo}/Dataset And Mapping/{el[1]}\"\n",
    "    else:\n",
    "        image_path = fr\"../../Dataset And Mapping/{el[1]}\"\n",
    "    \n",
    "    im = Image.open(image_path)\n",
    "    X.append(np.array(im).flatten() / 255)\n",
    "    Y.append(malware_family[el[2]])\n",
    "    i += 1\n",
    "    # print(i)\n",
    "\n",
    "print(f\"Done.\\nLast index: {i}.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea3d5d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bea3d5d4",
    "outputId": "f6e0a70c-3358-40f0-c1b8-7ebed0a64071",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.1) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Swizzor.gen!I\n",
      "\t- Test:  Swizzor.gen!I\n",
      "\n",
      "2.2) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Swizzor.gen!I\n",
      "\t- Test:  Swizzor.gen!I\n",
      "\n",
      "3.1) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Allaple.A\n",
      "\t- Test:  Allaple.A\n",
      "\n",
      "3.2) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Swizzor.gen!I\n",
      "\t- Test:  Swizzor.gen!I\n",
      "\n",
      "3.3) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Swizzor.gen!I\n",
      "\t- Test:  Swizzor.gen!I\n",
      "\n",
      "4.1) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Swizzor.gen!I\n",
      "\t- Test:  Swizzor.gen!I\n",
      "\n",
      "4.2) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Swizzor.gen!I\n",
      "\t- Test:  Swizzor.gen!I\n",
      "\n",
      "4.3) Malware family with the highest false classification (without normalizing - per iteration):\n",
      "\t- Train:  Swizzor.gen!I\n",
      "\t- Test:  Swizzor.gen!I\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, K\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     20\u001b[0m     (train_mean, test_mean, train_variance, test_variance, \n\u001b[1;32m     21\u001b[0m      cm_train, cm_test , train_false_classification_dict, test_false_classification_dict, \n\u001b[0;32m---> 22\u001b[0m      y_train_count, y_test_count) \u001b[38;5;241m=\u001b[39m \u001b[43mrun_StratifiedKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     _, images_by_class_names_count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(np\u001b[38;5;241m.\u001b[39marray(Y), return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m     images_names_count_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(class_names, images_by_class_names_count))\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mrun_StratifiedKFold\u001b[0;34m(X, Y, K)\u001b[0m\n\u001b[1;32m     31\u001b[0m gnb\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     32\u001b[0m     X_train,\n\u001b[1;32m     33\u001b[0m     y_train\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m y_hat_train \u001b[38;5;241m=\u001b[39m \u001b[43mgnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m cm_train \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(y_train, y_hat_train)\n\u001b[1;32m     39\u001b[0m cm_train_vector \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cm_train\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/naive_bayes.py:83\u001b[0m, in \u001b[0;36m_BaseNB.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     82\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X(X)\n\u001b[0;32m---> 83\u001b[0m jll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_joint_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(jll, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/sklearn/naive_bayes.py:490\u001b[0m, in \u001b[0;36mGaussianNB._joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    488\u001b[0m     jointi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_prior_[i])\n\u001b[1;32m    489\u001b[0m     n_ij \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_[i, :]))\n\u001b[0;32m--> 490\u001b[0m     n_ij \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(((\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_[i, :]), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    491\u001b[0m     joint_log_likelihood\u001b[38;5;241m.\u001b[39mappend(jointi \u001b[38;5;241m+\u001b[39m n_ij)\n\u001b[1;32m    493\u001b[0m joint_log_likelihood \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(joint_log_likelihood)\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_mean_list = []\n",
    "test_mean_list = []\n",
    "\n",
    "train_var_list = []\n",
    "test_var_list = []\n",
    "\n",
    "train_false_classification_list = []\n",
    "test_false_classification_list = []\n",
    "\n",
    "cm_train_vector = []\n",
    "cm_test_vector = []\n",
    "\n",
    "y_train_count_list = []\n",
    "y_test_count_list = []\n",
    "\n",
    "K = 10\n",
    "start = 2\n",
    "\n",
    "for k in range(start, K+1):\n",
    "    (train_mean, test_mean, train_variance, test_variance, \n",
    "     cm_train, cm_test , train_false_classification_dict, test_false_classification_dict, \n",
    "     y_train_count, y_test_count) = run_StratifiedKFold(X, Y, k)\n",
    "    \n",
    "    \n",
    "    _, images_by_class_names_count = np.unique(np.array(Y), return_counts=True)\n",
    "    images_names_count_dict = dict(zip(class_names, images_by_class_names_count))\n",
    "    \n",
    "    # Train:\n",
    "    for key in train_false_classification_dict:\n",
    "        train_false_classification_dict[key] = (train_false_classification_dict[key] * (1-1/K) * 1/K) * 1/images_names_count_dict[key]\n",
    "\n",
    "    # Test: \n",
    "    for key in test_false_classification_dict:\n",
    "        test_false_classification_dict[key] = (test_false_classification_dict[key] * 1/K * 1/K) * 1/images_names_count_dict[key]\n",
    "    \n",
    "    \n",
    "    train_mean_list.append(train_mean)\n",
    "    test_mean_list.append(test_mean)\n",
    "    \n",
    "    train_var_list.append(train_variance)\n",
    "    test_var_list.append(test_variance)\n",
    "    \n",
    "    train_false_classification_list.append(train_false_classification_dict)\n",
    "    test_false_classification_list.append(test_false_classification_dict)\n",
    "    \n",
    "    cm_train_vector.append(cm_train)\n",
    "    cm_test_vector.append(cm_test)\n",
    "    \n",
    "    y_train_count_list.append(y_train_count)\n",
    "    y_test_count_list.append(y_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc840dc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "cc840dc8",
    "outputId": "b231e290-4327-4e1e-a7dc-2a8a70cdb25d"
   },
   "outputs": [],
   "source": [
    "x = np.arange(start, K+1)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(x, train_mean_list, '--', x, test_mean_list, '--', marker=\"o\")\n",
    "plt.title(\"Success Rate Depending On K\", fontsize=20)\n",
    "plt.legend([\"Train\", \"Test\"], prop={'size': 16})\n",
    "plt.ylabel('Success Rate', fontsize=14)\n",
    "plt.xlabel('K', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(x, train_var_list, '--', x, test_var_list, '--', marker=\"o\")\n",
    "plt.title(\"Variance Depending On K\", fontsize=20)\n",
    "plt.legend([\"Train\", \"Test\"], prop={'size': 16})\n",
    "plt.ylabel('Variance', fontsize=14)\n",
    "plt.xlabel('K', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# print(\"train_var_list:\", train_var_list, \"test_var_list:\", test_var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229b2a5",
   "metadata": {
    "id": "9229b2a5"
   },
   "outputs": [],
   "source": [
    "# Giving weights to each vector per its K.\n",
    "test_avg_by_K =  1 / np.linspace(start, K, K - start + 1)\n",
    "train_avg_by_K = 1 - test_avg_by_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde8551",
   "metadata": {
    "id": "ccde8551"
   },
   "outputs": [],
   "source": [
    "# The combined success rate of Test & Train.\n",
    "overall_mean_success_rate = np.array(train_mean_list) * train_avg_by_K + np.array(test_mean_list) * test_avg_by_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b850571f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b850571f",
    "outputId": "ee35dfd8-aa4f-4199-c997-ff54a3e89764"
   },
   "outputs": [],
   "source": [
    "best_K = np.argmax(overall_mean_success_rate) + 2\n",
    "best_K_success_rate = overall_mean_success_rate[np.argmax(overall_mean_success_rate)]\n",
    "print(f\"The best K (AVG - Train && Test runs) is: K = {best_K}.\")\n",
    "print(f\"Total Success Rate for this K is (AVG - Train && Test): {(best_K_success_rate * 100):.3f} %.\")\n",
    "\n",
    "print(f\"\\n***\\tResults summary for this K ({best_K})\\t***\\n\")\n",
    "\n",
    "print(f\"- Success Rate:\")\n",
    "print(f\"\\tTrain:\\t {(train_mean_list[best_K-2] * 100):.3f} %\")\n",
    "print(f\"\\tTest:\\t {(test_mean_list[best_K-2] * 100):.3f} %\")\n",
    "\n",
    "print(f\"- Distribution Ratio:\")\n",
    "print(f\"\\tTrain:\\t {((1 - 1/best_K) * 100):.3f} %\")\n",
    "print(f\"\\tTest:\\t {((1/best_K) * 100):.3f} %\")\n",
    "\n",
    "print(f\"- Number Of Images (+/- 1):\")\n",
    "print(f\"\\tTotal:\\t  {len(Y)}\")\n",
    "print(f\"\\tTrain:\\t ~{((1 - 1/best_K)) * len(Y):.0f}\")\n",
    "print(f\"\\tTest:\\t ~{((1/best_K) * len(Y)):.0f}\")\n",
    "\n",
    "train_var_reverse_sort = np.sort(np.array(train_var_list))# [::-1]\n",
    "test_var_reverse_sort = np.sort(np.array(test_var_list)) # [::-1]\n",
    "\n",
    "print(f\"- Success Rate Variance:\")\n",
    "print(f\"\\t** The 1st place is the smallest (best) **\")\n",
    "print(f\"\\tTrain:\\t {(train_var_list[best_K-2]):.3e}, [{1 + np.where(train_var_reverse_sort == train_var_list[best_K-2])[0][0]}th place out of {len(train_var_reverse_sort)}]\")\n",
    "print(f\"\\tTest:\\t {(test_var_list[best_K-2]):.3e}, [{1 + np.where(test_var_reverse_sort == test_var_list[best_K-2])[0][0]}th place out of {len(test_var_reverse_sort)}]\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "labels = np.arange(len(class_names))\n",
    "width = 0.25\n",
    "ax.bar(labels-width/2-0.02, y_train_count_list[best_K-2], color=\"#a8c9a7\", width=width, align='center')\n",
    "ax.bar(labels+width/2+0.02, y_test_count_list[best_K-2], color=\"#b55e5f\", width=width, align='center')\n",
    "plt.title(\"Number Of Images By Family Name\", fontsize=22)\n",
    "fig.tight_layout()\n",
    "ax.set_xticks(labels)\n",
    "plt.xlim([-1, len(class_names)])\n",
    "ax.set_xticklabels(class_names)\n",
    "plt.xticks(rotation=90, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend([\"Train\", \"Test\"], prop={'size': 18})\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5cba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cm_train_vector)): \n",
    "    print(f\"\\n\\tK = {i+2}\")\n",
    "    \n",
    "    print(\"\\nSuccess Rate:\")\n",
    "    print(f\"\\t- Train: {(train_mean_list[i] * 100):.3f} %\")\n",
    "    print(f\"\\t- Test: {(test_mean_list[i] * 100):.3f} %\")\n",
    "    print(f\"\\t- AVG: {(overall_mean_success_rate[i] * 100):.3f} %\")\n",
    "    \n",
    "    print(\"\\n----------\")\n",
    "    \n",
    "    train_keys = list(train_false_classification_list[i])\n",
    "    train_argmax = np.argmax(np.array(list(train_false_classification_list[i].values())))\n",
    "\n",
    "    test_keys = list(test_false_classification_list[i])\n",
    "    test_argmax = np.argmax(np.array(list(test_false_classification_list[i].values())))\n",
    "    \n",
    "    print(\"\\nMalware family with the highest false classification (after normalizing):\")\n",
    "    print(\"\\t- Train:\", train_keys[train_argmax])\n",
    "    print(\"\\t- Test:\", test_keys[test_argmax])\n",
    "    \n",
    "    print(\"\\n----------\")\n",
    "    \n",
    "    mod.plot_confusion_matrix(\n",
    "        cm_train_vector[i], \n",
    "        'Train data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(i+2, train_mean_list[i]*100), \n",
    "        class_names\n",
    "    )\n",
    "\n",
    "    mod.plot_confusion_matrix(\n",
    "        cm_test_vector[i], \n",
    "        'Test data confusion matrix (K={})\\nSUCCESS RATE: {:.2f} %'.format(i+2, test_mean_list[i]*100), \n",
    "        class_names\n",
    "    )\n",
    "\n",
    "    mod.plot_hist(class_names, y_train_count_list[i], y_test_count_list[i], cm_train_vector[i], cm_test_vector[i])\n",
    "    \n",
    "    print(\"\\n******************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a655d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b53a655d",
    "outputId": "4b826d81-f1ee-4f1b-a922-541f01ab89dd"
   },
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "\n",
    "print(f\"\\t\\t\\t*************************************************\")\n",
    "print(f\"\\t\\t\\t*\\tStart time: {start_time}\\t*\")\n",
    "print(f\"\\t\\t\\t*\\tEnd time: {end_time} \\t*\")\n",
    "print(f'\\t\\t\\t*\\t\\x1b[0;30;43m' + f\"Duration time: {str(end_time - start_time)}\" + '\\x1b[0m\\t\\t*')\n",
    "print(f\"\\t\\t\\t*************************************************\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "model_32x32.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
