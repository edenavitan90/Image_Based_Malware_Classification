from sklearn.model_selection import StratifiedKFold

import numpy as np

from sklearn import metrics
from pathlib import Path
from keras.layers import *
from keras.models import Sequential
from keras.models import model_from_json

malware_family = {"Adialer.C": 0, "Agent.FYI": 1, "Allaple.A": 2, "Allaple.L": 3, "Alueron.gen!J": 4, "Autorun.K": 5, "C2LOP.gen!g": 6,
                  "C2LOP.P": 7, "Dialplatform.B": 8, "Dontovo.A": 9, "Fakerean": 10, "Instantaccess": 11, "Lolyda.AA1": 12, "Lolyda.AA2": 13,
                  "Lolyda.AA3": 14, "Lolyda.AT": 15, "Malex.gen!J": 16, "Obfuscator.AD": 17, "Rbot!gen": 18, "Skintrim.N": 19, "Swizzor.gen!E": 20,
                  "Swizzor.gen!I": 21, "VB.AT": 22, "Wintrim.BX": 23, "Yuner.A": 24}

class_names = np.array(["Adialer.C", "Agent.FYI", "Allaple.A", "Allaple.L", "Alueron.gen!J", "Autorun.K", "C2LOP.gen!g",
                  "C2LOP.P", "Dialplatform.B", "Dontovo.A", "Fakerean", "Instantaccess", "Lolyda.AA1", "Lolyda.AA2",
                  "Lolyda.AA3", "Lolyda.AT", "Malex.gen!J", "Obfuscator.AD", "Rbot!gen", "Skintrim.N", "Swizzor.gen!E",
                  "Swizzor.gen!I", "VB.AT", "Wintrim.BX", "Yuner.A"])

def create_model(size):
    # Define the model:
    model = Sequential()

    # size == 32 OR 64 OR 128.
    model.add(Conv2D(size, (3, 3), padding='same', input_shape=(size, size, 1), activation="relu"))
    model.add(Conv2D(32, (3, 3), activation="relu"))
    # model.add(Conv2D(size, (3, 3), activation="relu"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3, 3), padding='same', activation="relu"))
    model.add(Conv2D(64, (3, 3), activation="relu"))
    # model.add(Conv2D(2 * size, (3, 3), padding='same', activation="relu"))
    # model.add(Conv2D(2 * size, (3, 3), activation="relu"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(512, activation="relu"))
    model.add(Dropout(0.5))
    model.add(Dense(len(malware_family), activation="softmax"))

    return model


def run_StratifiedKFold(X, Y, K, size):
    skf = StratifiedKFold(n_splits=K, random_state=1, shuffle=True)

    X = np.array(X)
    Y = np.array(Y)
    train_success = []
    test_success = []
    train_false_classification_total = []
    test_false_classification_total = []
    cm_train_vector = np.zeros((class_names.shape[0], class_names.shape[0]))
    cm_test_vector = np.zeros((class_names.shape[0], class_names.shape[0]))

    y_train_count_mean_array = np.zeros(len(class_names))
    y_test_count_mean_array = np.zeros(len(class_names))

    it = 0
    for train_index, test_index in skf.split(X, Y):
        it += 1

        model = create_model(size)

        print(f"Model Summary:\n")
        model.summary()

        model.compile(
            loss='categorical_crossentropy',
            # loss="mse",
            optimizer='adam',
            metrics=['accuracy']
        )

        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = Y[train_index], Y[test_index]

        _, train_count = np.unique(y_train, return_counts=True)
        _, test_count = np.unique(y_test, return_counts=True)

        y_train_count_mean_array += np.array(train_count)
        y_test_count_mean_array += np.array(test_count)

        y_train_cnn = []
        for idx in y_train:
            y_temp = np.zeros(len(class_names))
            y_temp[idx] = 1
            y_train_cnn.append(y_temp)
        y_train_cnn = np.array(y_train_cnn)

        # print(np.array(X_train).shape)
        # print(np.array(y_train_cnn).shape)

        # Train the model:
        print(f"\n{K}.{it}) Model Fit:\n")
        model.fit(
            X_train,
            y_train_cnn,
            batch_size=32,
            # batch_size=60,
            epochs=10,
            # epochs=50,
            # validation_data=(np.array(x_test), np.array(y_test)),
            shuffle=True,
            verbose=2
        )
        print("\n----------")

        # Save neural network structure
        # model_structure = model.to_json()
        # f = Path("artifacts/32x32/32x32_model_structure_10_epochs.json")
        # f.write_text(model_structure)

        # Save neural network's trained weights
        # model.save_weights("artifacts/32x32/32x32_model_weights_10_epochs.h5")

        train_results = model.predict(X_train)
        test_results = model.predict(X_test)

        # Train
        y_hat_train = np.argmax(train_results, axis=1)
        cm_train = metrics.confusion_matrix(y_train, y_hat_train)
        cm_train_vector += cm_train

        # Test
        y_hat_test = np.argmax(test_results, axis=1)
        cm_test = metrics.confusion_matrix(y_test, y_hat_test)
        cm_test_vector += cm_test

        train_success_rate = (y_hat_train == y_train).sum() / len(y_train)
        test_success_rate = (y_hat_test == y_test).sum() / len(y_test)
        train_success.append(train_success_rate)
        test_success.append(test_success_rate)

        train_false_classification = class_names[y_train[np.where((y_hat_train == y_train) == False)]]
        train_false_classification_total += train_false_classification.tolist()
        if len(train_false_classification.tolist()) > 0:
            train_false_classification_labels, train_false_classification_count = np.unique(train_false_classification,
                                                                                            return_counts=True)
            train_false_classification_to_print = \
                f"{train_false_classification_labels[np.argmax(train_false_classification_count)]} (# of appearance: {train_false_classification_count[np.argmax(train_false_classification_count)]} out of {len(train_false_classification)} [{len(y_train)} tested])"
        else:
            train_false_classification_to_print = f"N/A"

        test_false_classification = class_names[y_test[np.where((y_hat_test == y_test) == False)]]
        test_false_classification_total += test_false_classification.tolist()
        if len(test_false_classification.tolist()) > 0:
            test_false_classification_labels, test_false_classification_count = np.unique(test_false_classification,
                                                                                          return_counts=True)
            test_false_classification_to_print = \
                f"{test_false_classification_labels[np.argmax(test_false_classification_count)]} (# of appearance: {test_false_classification_count[np.argmax(test_false_classification_count)]} out of {len(test_false_classification)} [{len(y_test)} tested])"
        else:
            test_false_classification_to_print = f"N/A"

        print(f"\n{K}.{it}) Success Rate (without normalizing - per iteration):\n"
              f"\t- Train: {(train_success_rate * 100):.3f} %\n"
              f"\t- Test: {(test_success_rate * 100):.3f} %\n"
              f"     Malware family with the highest false classification (without normalizing - per iteration):\n"
              f"\t- Train: {train_false_classification_to_print}\n"
              f"\t- Test: {test_false_classification_to_print}\n"
              f"\n----------")

    train_false_classification_lables, train_false_classification_count = np.unique(
        np.array(train_false_classification_total), return_counts=True)
    test_false_classification_lables, test_false_classification_count = np.unique(
        np.array(test_false_classification_total), return_counts=True)

    train_false_classification_dict = dict(zip(train_false_classification_lables, train_false_classification_count))
    test_false_classification_dict = dict(zip(test_false_classification_lables, test_false_classification_count))

    train_mean = np.mean(train_success)
    test_mean = np.mean(test_success)

    train_variance = np.var(train_success)
    test_variance = np.var(test_success)

    return (train_mean, test_mean, train_variance, test_variance,
            cm_train_vector / K, cm_test_vector / K, train_false_classification_dict, test_false_classification_dict,
            y_train_count_mean_array / K, y_test_count_mean_array / K)

